#!/bin/bash
#SBATCH --job-name=blip3o_cpu_eval
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=32
#SBATCH --time=6:00:00
#SBATCH --mem=64G
#SBATCH --output=./slurm_out/blip3o_cpu_eval_%j.out
#SBATCH --error=./slurm_out/blip3o_cpu_eval_%j.err

# =============================================================================
# CPU-OPTIMIZED BLIP3-o Evaluation Job for Snellius
# Optimized for CPU-only evaluation with embeddings
# =============================================================================

echo "üíª CPU-Optimized BLIP3-o Evaluation on Snellius"
echo "============================================================="
echo "üéØ CPU CONFIGURATION:"
echo "  ‚úÖ Partition: CPU (no GPU required)"
echo "  ‚úÖ CPUs: 32 cores for parallel processing"
echo "  ‚úÖ Memory: 64GB for large embedding processing"
echo "  ‚úÖ Time: 6 hours (generous for CPU evaluation)"
echo "  ‚úÖ CUDA disabled - pure CPU evaluation"
echo "============================================================="
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "CPU Info: $(lscpu | grep 'Model name' | head -1)"
echo "Available CPUs: $(nproc)"
echo "Available Memory: $(free -h | grep Mem | awk '{print $2}')"
echo "============================================================="

cd $SLURM_SUBMIT_DIR

# Setup environment for CPU-only processing
module purge
module load 2024
module load Miniconda3/24.7.1-0
# NOTE: No CUDA module needed for CPU evaluation

# Activate environment
source activate eva_clip_env

# CPU-OPTIMIZED: Set environment variables for optimal CPU performance
export OMP_NUM_THREADS=16  # Use half the allocated CPUs
export MKL_NUM_THREADS=16  # Intel MKL optimization
export OPENBLAS_NUM_THREADS=16  # OpenBLAS optimization
export NUMEXPR_NUM_THREADS=16  # NumExpr optimization

# Disable CUDA completely
export CUDA_VISIBLE_DEVICES=""
export TORCH_USE_CUDA_DSA=0

echo "üîß CPU Optimization Settings:"
echo "   OMP_NUM_THREADS: $OMP_NUM_THREADS"
echo "   MKL_NUM_THREADS: $MKL_NUM_THREADS"
echo "   CUDA_VISIBLE_DEVICES: '$CUDA_VISIBLE_DEVICES' (disabled)"

# Configuration - UPDATE THESE PATHS FOR YOUR SETUP
MODEL_PATH="/scratch-shared/scur2711/blip3o_workspace/checkpoints/blip3o_fixed_patch_only_13283695_20250724_165821"
EMBEDDINGS_DIR="/scratch-shared/scur2711/blip3o_workspace/embeddings/chunked_256_tokens"
OUTPUT_DIR="./cpu_eval_results_$(date +%Y%m%d_%H%M%S)"
TRAINING_MODE="auto"

# CPU-OPTIMIZED: Smaller defaults for CPU evaluation
NUM_SAMPLES=500          # Reduced for CPU (can increase if time permits)
BATCH_SIZE=4             # Smaller batch size for CPU memory
NUM_INFERENCE_STEPS=25   # Reduced inference steps for CPU speed
CPU_THREADS=16           # Explicit CPU thread control

# Create directories
mkdir -p "${OUTPUT_DIR}"
mkdir -p ./slurm_out

echo ""
echo "‚öôÔ∏è CPU Evaluation Configuration:"
echo "============================"
echo "Model Path: $MODEL_PATH"
echo "Embeddings: $EMBEDDINGS_DIR"
echo "Output: $OUTPUT_DIR"
echo "Training Mode: $TRAINING_MODE"
echo "Samples: $NUM_SAMPLES (CPU-optimized)"
echo "Batch Size: $BATCH_SIZE (CPU-optimized)"
echo "Inference Steps: $NUM_INFERENCE_STEPS (CPU-optimized)"
echo "CPU Threads: $CPU_THREADS"
echo ""

# Verify paths exist
echo "üîç Verifying paths..."
echo "==================="

# Check model path
if [ ! -d "$MODEL_PATH" ]; then
    echo "‚ùå ERROR: Model path not found: $MODEL_PATH"
    echo "Available checkpoints:"
    ls -la "/scratch-shared/scur2711/blip3o_workspace/checkpoints/" 2>/dev/null || echo "No checkpoints directory found"
    exit 1
else
    echo "‚úÖ Model path verified: $MODEL_PATH"
    echo "   Model files:"
    ls -la "$MODEL_PATH"/*.{bin,safetensors,json} 2>/dev/null | head -5
fi

# Check embeddings path
if [ ! -d "$EMBEDDINGS_DIR" ]; then
    echo "‚ùå ERROR: Embeddings path not found: $EMBEDDINGS_DIR"
    echo "Available embeddings:"
    ls -la "/scratch-shared/scur2711/blip3o_workspace/embeddings/" 2>/dev/null || echo "No embeddings directory found"
    exit 1
else
    echo "‚úÖ Embeddings path verified: $EMBEDDINGS_DIR"
    if [ -f "$EMBEDDINGS_DIR/embeddings_manifest.json" ]; then
        echo "   Manifest found:"
        head -10 "$EMBEDDINGS_DIR/embeddings_manifest.json"
    fi
fi

# Check evaluation script
if [ ! -f "eval_blip3o_patch_similarity.py" ]; then
    echo "‚ùå ERROR: Evaluation script not found: eval_blip3o_patch_similarity.py"
    echo "Available Python files:"
    ls -la *.py
    exit 1
else
    echo "‚úÖ Evaluation script verified: eval_blip3o_patch_similarity.py"
fi

echo ""
echo "üöÄ Starting CPU-Optimized Evaluation..."
echo "======================================"
echo "This will perform comprehensive cosine similarity evaluation:"
echo "  1. üéØ Per-patch cosine similarity (for each of 256/257 patches)"
echo "  2. üìä Per-image cosine similarity (average of all patches per image)"
echo "  3. üåê Global cosine similarity (average across all images)"
echo "  4. üìà Quality distribution analysis"
echo "  5. üìã Comprehensive JSON reporting"
echo ""
echo "Expected processing time: 30-60 minutes on CPU"
echo "Progress will be logged every 5 batches."
echo ""

# Start timer
EVAL_START_TIME=$(date +%s)

# Launch CPU-optimized evaluation
echo "‚ñ∂Ô∏è  Launching evaluation at $(date)..."
python eval_blip3o_patch_similarity_cpu.py.py \
    --model_path "$MODEL_PATH" \
    --chunked_embeddings_dir "$EMBEDDINGS_DIR" \
    --output_dir "$OUTPUT_DIR" \
    --training_mode "$TRAINING_MODE" \
    --num_samples $NUM_SAMPLES \
    --batch_size $BATCH_SIZE \
    --num_inference_steps $NUM_INFERENCE_STEPS \
    --max_eval_shards 1 \
    --cpu_threads $CPU_THREADS \
    --memory_efficient \
    --progress_frequency 5 \
    --same_data_eval \
    --normalize_embeddings \
    --save_detailed_results \
    --device cpu \
    --torch_dtype float32

EXIT_CODE=$?
EVAL_END_TIME=$(date +%s)
EVAL_DURATION=$((EVAL_END_TIME - EVAL_START_TIME))

# Results analysis
echo ""
echo "========================================================================"
echo "üìä CPU-OPTIMIZED BLIP3-O EVALUATION RESULTS"
echo "========================================================================"
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $(hostname)"
echo "Evaluation Type: CPU-Optimized Cosine Similarity Analysis"
echo "Evaluation Duration: $EVAL_DURATION seconds ($((EVAL_DURATION/60)) minutes)"
echo "Total Runtime: $SECONDS seconds"
echo "Date: $(date)"

if [ $EXIT_CODE -eq 0 ]; then
    echo "Status: ‚úÖ SUCCESS - CPU EVALUATION COMPLETED"
    
    # Find and display results
    RESULTS_FILES=("$OUTPUT_DIR"/*results*.json)
    
    echo ""
    echo "üìä CPU EVALUATION RESULTS SUMMARY:"
    echo "================================="
    
    # Parse and display results
    if [ ${#RESULTS_FILES[@]} -gt 0 ] && [ -f "${RESULTS_FILES[0]}" ]; then
        echo "üìã Results File: ${RESULTS_FILES[0]}"
        
        # Extract key metrics using python
        python -c "
import json
import sys

try:
    with open('${RESULTS_FILES[0]}', 'r') as f:
        data = json.load(f)
    
    if 'results_summary' in data:
        results = data['results_summary']
        print()
        print(f'üéØ COSINE SIMILARITY RESULTS:')
        print(f'   Overall cosine similarity:    {results.get(\"overall_cosine_similarity\", 0):.4f}')
        print(f'   Per-image mean similarity:    {results.get(\"per_image_mean_similarity\", 0):.4f}')
        print(f'   High quality images (>0.7):  {results.get(\"high_quality_images_percentage\", 0):.1f}%')
        print(f'   Total images evaluated:       {results.get(\"total_images\", 0):,}')
        print(f'   Total patches evaluated:      {results.get(\"total_patches\", 0):,}')
        print()
        
        # CPU performance assessment
        overall_sim = results.get('overall_cosine_similarity', 0)
        if overall_sim > 0.8:
            print(f'üéâ EXCELLENT: Outstanding patch-level alignment on CPU!')
            print(f'üöÄ Model shows excellent overfitting - CPU evaluation successful')
        elif overall_sim > 0.6:
            print(f'‚úÖ VERY GOOD: Strong patch-level performance on CPU')
            print(f'üéØ Model successfully learned patch-level mapping')
        elif overall_sim > 0.4:
            print(f'üîÑ GOOD: Solid patch-level learning detected')
            print(f'üí° Model shows promise, CPU evaluation completed')
        else:
            print(f'‚ö†Ô∏è  NEEDS IMPROVEMENT: Low patch-level similarity')
            print(f'üí° Consider longer training or hyperparameter tuning')
    
    if 'cpu_configuration' in data:
        cpu_config = data['cpu_configuration']
        print()
        print(f'üíª CPU CONFIGURATION USED:')
        print(f'   CPU threads:         {cpu_config.get(\"cpu_threads\", \"unknown\")}')
        print(f'   Memory efficient:    {cpu_config.get(\"memory_efficient\", \"unknown\")}')
        print(f'   Batch size:          {cpu_config.get(\"batch_size\", \"unknown\")}')
        print(f'   Inference steps:     {cpu_config.get(\"inference_steps\", \"unknown\")}')
    
    print()
    print(f'üíæ Detailed results saved to: $OUTPUT_DIR')

except Exception as e:
    print(f'‚ùå Could not parse results: {e}')
    sys.exit(1)
"
    else
        echo "‚ö†Ô∏è  No results file found, but evaluation may have completed"
    fi
    
    # Show output directory contents
    echo ""
    echo "üìÅ Generated Files:"
    echo "=================="
    ls -la "$OUTPUT_DIR"
    
    echo ""
    echo "‚úÖ CPU EVALUATION COMPLETED SUCCESSFULLY"
    echo ""
    echo "üìã What was evaluated on CPU:"
    echo "   ‚úÖ Per-patch cosine similarity for each patch in each image"
    echo "   ‚úÖ Per-image average cosine similarity (mean of all patches)"
    echo "   ‚úÖ Global average cosine similarity (mean across all images)"
    echo "   ‚úÖ Quality distribution analysis and thresholds"
    echo "   ‚úÖ Comprehensive JSON reporting for further analysis"
    echo ""
    echo "üéØ CPU Evaluation Benefits:"
    echo "   ‚Ä¢ No GPU dependencies - works on any CPU node"
    echo "   ‚Ä¢ Memory efficient processing for large datasets"
    echo "   ‚Ä¢ Reliable evaluation using pre-computed embeddings"
    echo "   ‚Ä¢ Detailed performance metrics and quality analysis"
    echo ""
    echo "üìä Next Steps:"
    echo "   ‚Ä¢ Review the comprehensive results in: $OUTPUT_DIR"
    echo "   ‚Ä¢ Analyze the quality distribution and similarity scores"
    echo "   ‚Ä¢ Use results to assess model overfitting performance"
    echo "   ‚Ä¢ Compare with training metrics if available"
    
else
    echo "Status: ‚ùå FAILED"
    echo ""
    echo "‚ùå CPU EVALUATION FAILED WITH EXIT CODE: $EXIT_CODE"
    echo ""
    echo "üîç CPU Troubleshooting:"
    echo "   1. Check that model path is correct and accessible"
    echo "   2. Verify embeddings directory and manifest file exist"
    echo "   3. Ensure sufficient CPU memory is available"
    echo "   4. Try reducing --batch_size to 2 for lower memory usage"
    echo "   5. Try reducing --num_samples for faster testing"
    echo "   6. Check Python environment and dependencies"
    echo "   7. Verify model and embeddings compatibility"
    echo ""
    echo "üìÇ Log files:"
    echo "   Output: ./slurm_out/blip3o_cpu_eval_${SLURM_JOB_ID}.out"
    echo "   Error:  ./slurm_out/blip3o_cpu_eval_${SLURM_JOB_ID}.err"
    echo ""
    echo "üîß Quick fixes to try:"
    echo "   ‚Ä¢ Reduce batch size: add --batch_size 2 to the command"
    echo "   ‚Ä¢ Reduce samples: add --num_samples 100 for quick test"
    echo "   ‚Ä¢ Check paths: verify MODEL_PATH and EMBEDDINGS_DIR"
    echo "   ‚Ä¢ Memory: request more memory with #SBATCH --mem=128G"
fi

echo ""
echo "========================================================================"
echo "üèÅ CPU EVALUATION SUMMARY"
echo "========================================================================"

# Resource usage summary
echo "üìä Resource Usage:"
echo "   Job ID: $SLURM_JOB_ID"
echo "   Node: $(hostname)"
echo "   CPUs allocated: $SLURM_CPUS_PER_TASK"
echo "   Memory allocated: $SLURM_MEM_PER_NODE MB"
echo "   CPU evaluation time: $EVAL_DURATION seconds ($((EVAL_DURATION/60)) minutes)"
echo "   Total job time: $SECONDS seconds ($((SECONDS/60)) minutes)"

# Final status
if [ $EXIT_CODE -eq 0 ]; then
    echo ""
    echo "üéâ SUCCESS: CPU evaluation completed successfully!"
    echo ""
    echo "üìã Accomplished on CPU:"
    echo "   ‚úÖ Comprehensive cosine similarity analysis without GPU"
    echo "   ‚úÖ Per-patch, per-image, and global similarity computation"
    echo "   ‚úÖ Memory-efficient processing optimized for CPU"
    echo "   ‚úÖ Detailed JSON reporting and quality analysis"
    echo "   ‚úÖ Reliable evaluation using pre-computed embeddings"
    echo ""
    echo "üéØ Key Benefits of CPU Evaluation:"
    echo "   ‚Ä¢ No GPU queue waiting time"
    echo "   ‚Ä¢ Reliable and reproducible results"
    echo "   ‚Ä¢ Cost-effective for evaluation tasks"
    echo "   ‚Ä¢ Works with any CPU allocation on Snellius"
else
    echo ""
    echo "‚ùå FAILURE: CPU evaluation encountered issues"
    echo ""
    echo "üí° Recommendations:"
    echo "   ‚Ä¢ Check the error logs above for specific issues"
    echo "   ‚Ä¢ Verify all paths are accessible from compute node"
    echo "   ‚Ä¢ Try with smaller batch size and sample count"
    echo "   ‚Ä¢ Ensure embeddings are compatible with model"
    echo "   ‚Ä¢ Contact support if paths are correct but evaluation fails"
fi

echo "========================================================================"

echo "üèÅ CPU evaluation job completed at $(date)"

exit $EXIT_CODE