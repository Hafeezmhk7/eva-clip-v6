#!/bin/bash
#SBATCH --job-name=blip3o_eval
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=16
#SBATCH --time=2:00:00
#SBATCH --mem=32G
#SBATCH --output=./slurm_out/blip3o_eval_%j.out
#SBATCH --error=./slurm_out/blip3o_eval_%j.err

# =============================================================================
# BLIP3-o Evaluation - Patch-wise Cosine Similarity
# Clean and robust evaluation script
# =============================================================================

echo "ğŸ” BLIP3-o Patch-wise Cosine Similarity Evaluation"
echo "=================================================="
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | head -1)"
echo "=================================================="

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# Configuration
CHECKPOINTS_BASE="/scratch-shared/azadaianchuk1/blip3o_workspace/checkpoints"
EMBEDDINGS_DIR="/scratch-shared/azadaianchuk1/blip3o_workspace/embeddings/patch_only_256_tokens"
OUTPUT_DIR="./eval_results_$(date +%Y%m%d_%H%M%S)"

# Create output directory
mkdir -p "${OUTPUT_DIR}"
mkdir -p ./slurm_out

echo ""
echo "ğŸ” Finding trained model..."
echo "========================="

# Automatically find the most recent trained model
POSSIBLE_MODELS=(
    "${CHECKPOINTS_BASE}/fixed_training_patch_only_*"
    "${CHECKPOINTS_BASE}/training_fixed_patch_only_*"
    "${CHECKPOINTS_BASE}/*patch_only*"
    "${CHECKPOINTS_BASE}/*training*"
)

MODEL_PATH=""
for pattern in "${POSSIBLE_MODELS[@]}"; do
    for path in $pattern; do
        if [ -d "$path" ] && [ -f "$path/config.json" ] && { [ -f "$path/model.safetensors" ] || [ -f "$path/pytorch_model.bin" ]; }; then
            MODEL_PATH="$path"
            echo "âœ… Found model: $MODEL_PATH"
            break 2
        fi
    done
done

if [ -z "$MODEL_PATH" ]; then
    echo "âŒ No trained model found!"
    echo "Available checkpoints:"
    ls -la "$CHECKPOINTS_BASE" 2>/dev/null || echo "No checkpoints directory"
    echo ""
    echo "Please train a model first or update the CHECKPOINTS_BASE path."
    exit 1
fi

# Verify embeddings
if [ ! -d "$EMBEDDINGS_DIR" ]; then
    echo "âŒ Embeddings not found: $EMBEDDINGS_DIR"
    echo "Available embeddings:"
    ls -la "/scratch-shared/azadaianchuk1/blip3o_workspace/embeddings/" 2>/dev/null
    exit 1
fi

echo "âœ… Embeddings verified: $EMBEDDINGS_DIR"

# Verify evaluation script
if [ ! -f "eval_blip3o_patch_similarity.py" ]; then
    echo "âŒ Evaluation script not found!"
    exit 1
fi

echo "âœ… Evaluation script found"

echo ""
echo "âš™ï¸ Configuration:"
echo "================"
echo "Model: $MODEL_PATH"
echo "Embeddings: $EMBEDDINGS_DIR"
echo "Output: $OUTPUT_DIR"
echo ""

# Model info
echo "ğŸ“‹ Model files:"
ls -la "$MODEL_PATH"/*.{json,safetensors,bin} 2>/dev/null

echo ""
echo "ğŸš€ Starting evaluation..."
echo "========================"

# Launch evaluation
python eval_blip3o_patch_similarity.py \
    --model_path "$MODEL_PATH" \
    --chunked_embeddings_dir "$EMBEDDINGS_DIR" \
    --output_dir "$OUTPUT_DIR" \
    --training_mode auto \
    --num_samples 1000 \
    --batch_size 8 \
    --num_inference_steps 50 \
    --same_data_eval \
    --normalize_embeddings \
    --device auto \
    --torch_dtype float32

EXIT_CODE=$?

echo ""
echo "========================================"
echo "ğŸ“Š Evaluation Results"
echo "========================================"

if [ $EXIT_CODE -eq 0 ]; then
    echo "âœ… Evaluation completed successfully!"
    
    # Find and display results
    RESULTS_FILE=$(find "$OUTPUT_DIR" -name "*results*.json" | head -1)
    
    if [ -f "$RESULTS_FILE" ]; then
        echo ""
        echo "ğŸ“‹ Results Summary:"
        echo "=================="
        
        # Extract key metrics
        python -c "
import json
try:
    with open('$RESULTS_FILE', 'r') as f:
        data = json.load(f)
    
    if 'results_summary' in data:
        r = data['results_summary']
        print(f'ğŸ¯ Overall Cosine Similarity: {r.get(\"overall_cosine_similarity\", 0):.4f}')
        print(f'ğŸ“Š Per-image Mean: {r.get(\"per_image_mean_similarity\", 0):.4f}')
        print(f'ğŸ“Š Per-patch Mean: {r.get(\"per_patch_mean_similarity\", 0):.4f}')
        print(f'ğŸ“ˆ High Quality Images (>0.7): {r.get(\"high_quality_images_percentage\", 0):.1f}%')
        print(f'ğŸ“ˆ Images Evaluated: {r.get(\"total_images\", 0):,}')
        
        # Assessment
        sim = r.get('overall_cosine_similarity', 0)
        if sim > 0.8:
            print('ğŸ‰ EXCELLENT performance!')
        elif sim > 0.6:
            print('âœ… VERY GOOD performance!')
        elif sim > 0.4:
            print('ğŸ”„ GOOD performance!')
        elif sim > 0.2:
            print('ğŸ“ˆ Shows learning!')
        else:
            print('âš ï¸ Needs improvement')
            
except Exception as e:
    print(f'Could not parse results: {e}')
"
        
        echo ""
        echo "ğŸ“ Results saved to: $OUTPUT_DIR"
        echo "ğŸ“„ Full results: $RESULTS_FILE"
    else
        echo "âš ï¸ No results file found"
    fi
    
    echo ""
    echo "âœ… SUCCESS: Evaluation completed!"
    
else
    echo "âŒ FAILED: Exit code $EXIT_CODE"
    echo ""
    echo "ğŸ’¡ Troubleshooting:"
    echo "  â€¢ Check log files in ./slurm_out/"
    echo "  â€¢ Verify model and embeddings paths"
    echo "  â€¢ Try smaller batch size: --batch_size 4"
    echo "  â€¢ Try fewer samples: --num_samples 100"
fi

echo ""
echo "ğŸ Job completed at $(date)"
echo "========================================"

exit $EXIT_CODE