ğŸ”„ Weights & Biases initialized:
    Project: unified_3D
    Experiment: alignment_of_eva_clip_20250708_134640
    URL: https://wandb.ai/RecSys-UvA/unified_3D/runs/ckr53w7k
ğŸ“š Loading dataset from embeddings/blip3o_embeddings.pkl
    Train samples: 2381
    Val samples: 265
ğŸš€ Initializing DiT Model for EVA-CLIP â†’ CLIP Translation...
    Input (CLIP L-14): 768D
    Condition (EVA-CLIP): 1280D
    Architecture: enhanced
    ğŸ¯ Attention config: 16 heads, 8 KV heads
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
    ğŸ¯ Time-Aware Context Drop initialized:
        Drop ratio: 0.25
        Training only: True
        Min context length: 1
    âš¡ Grouped Query Attention with Context Drop:
        Heads: 16/8
        Context drop ratio: 0.25
ğŸš€ Enhanced LuminaDiT (Lumina-Next + Context Drop) initialized:
    Architecture: 24 blocks, 16 heads, 1024 dim
    Input: CLIP L-14 (768D) â†’ EVA-CLIP (1280D)
    AdaLN-Zero: Enabled for proper time conditioning
    Grouped QA: 16/8 heads
    KQ-Norm: Enabled
    Context Drop: Enabled
    Drop Ratio: 0.25
    Zero-init: Enabled for training stability
    SwiGLU: Modern transformer activation
    âœ¨ Using Enhanced DiT Architecture (Lumina-Next)
    ğŸ”„ AdaLN-Zero: Enabled for proper time conditioning
    ğŸ¯ Grouped Query Attention: 16/8 heads
    ğŸ›¡ï¸ KQ-Norm: Enabled for training stability
    ğŸ”§ Zero-init: Enabled for output projections
    ğŸš€ SwiGLU: Modern transformer activation
ğŸ“Š Model Statistics:
    Total parameters: 464,493,312
    Trainable parameters: 464,493,312
    Model size: 1858.0 MB
    Model type: Enhanced_LuminaNext
ğŸš€ Enhanced Flow Matching Loss initialized:
    Loss type: huber
    Sigmoid scheduling: Enabled
    Embedding task optimizations: Enabled
    Stability weight: 0.1
ğŸ¯ Training Configuration:
    Learning rate: 0.0002
    Epochs: 100
    Batch size: 64
    DiT Architecture: enhanced
    Model Implementation: Enhanced_LuminaNext
    Loss type: huber
    Scheduler: cosine_restarts
    W&B Logging: Enabled
Epoch 1/100:  21%|â–ˆâ–ˆ        | 8/38 [00:02<00:05,  5.64it/s, loss=1.2212, avg_loss=1.3135, align=0.010, lr=2.00e-04, arch=enhanced]Exception ignored in: <generator object tqdm.__iter__ at 0x14b2218de440>Exception ignored in sys.unraisablehook: <built-in function unraisablehook>
